{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "private_outputs": true,
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2vRK7JsFY4IV"
   },
   "outputs": [],
   "source": [
    "!pip install openai\n",
    "import requests\n",
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "API_KEY = \"\"\n",
    "API_ENDPOINT = \"https://api.openai.com/v1/chat/completions\"\n",
    "openai.api_key = API_KEY"
   ],
   "metadata": {
    "id": "HL-i-kXJRI1i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open('/content/drive/MyDrive/MacawProject/optional_dims.txt', 'r') as optional_dims:\n",
    "  optional_dims_content = optional_dims.read()"
   ],
   "metadata": {
    "id": "fztXNZJ_47ed"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "I initialized '/content/drive/MyDrive/MacawProject/dimensions_prompt.txt' with:\n",
    "\"You are given a SITUATION and possible answers for the situation in ANSWERS. Your task is to choose the best four dimensions that will help you find the correct answer on the SITUATION.\n",
    "After you chose the dimensions, please elaborate the scene on these dimensions.\n",
    "Inputs: OPTIONAL_DIMENSIONS, SITUATION, ANSWERS\n",
    "Outputs: CHOSEN_DIMENSIONS, ELABORATIONS\n",
    "OPTIONAL_DIMENSIONS:\"\n",
    "then the dimensions as in optional_dims."
   ],
   "metadata": {
    "id": "CLMZMoHAOsM8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "def read_situation_from_json(file_path, is_train):\n",
    "  situation_data = []\n",
    "  with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "      data = json.loads(line)\n",
    "      id = data.get('id')\n",
    "      question = data.get('question')\n",
    "      possible_ans = data.get('mcoptions')\n",
    "      answer = data.get('answer')\n",
    "      d = {}\n",
    "      d['id'] = id\n",
    "      d['question'] = question\n",
    "      d['mcoptions'] = possible_ans\n",
    "      d['answer'] = answer\n",
    "      if is_train:\n",
    "        chosen_dims = data.get('chosen_dimensions')\n",
    "        elaborations = data.get('elaboration')\n",
    "        d['chosen_dimensions'] = chosen_dims\n",
    "        d['elaboration'] = elaborations\n",
    "      situation_data.append(d)\n",
    "  return situation_data\n",
    "\n",
    "\n",
    "def append_dims_elaborations_to_few_shot_prompt(output_prompt_filename, situation, dims, elaborations):\n",
    "  with open(output_prompt_filename, 'a') as prompt_file:\n",
    "    prompt_file.write('Inputs:\\n')\n",
    "    prompt_file.write('SITUATION: ' + situation['question'] + '\\n')\n",
    "    prompt_file.write('ANSWERS: ' + situation['mcoptions'] + '\\n')\n",
    "    prompt_file.write('Outputs:\\n')\n",
    "    prompt_file.write('CHOSEN_DIMENSIONS:\\n' + dims)\n",
    "    prompt_file.write('ELABORATIONS:' + elaborations + '\\n')\n",
    "\n",
    "\n",
    "def generate_few_shot_prompt(in_context_samples_filename, output_prompt_filename):\n",
    "  situations = read_situation_from_json(in_context_samples_filename, True)\n",
    "  for situation in situations:\n",
    "    dims = \"\"\n",
    "    elaborations = \"\"\n",
    "    for d in situation['chosen_dimensions']:\n",
    "      dims += d + '\\n'\n",
    "    elaborations += situation['elaboration'].replace(\" [\", \"\\n[\")\n",
    "    append_dims_elaborations_to_few_shot_prompt(output_prompt_filename, situation, dims, elaborations)\n",
    "\n",
    "in_context_samples_filename = \"/content/drive/MyDrive/MacawProject/in_context_few_shots.jsonl\"\n",
    "output_prompt_filename = '/content/drive/MyDrive/MacawProject/dimensions_prompt.txt'\n",
    "# generate_few_shot_prompt(in_context_samples_filename, output_prompt_filename)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "aMdligWFJv2M"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Call GPT-3.5 on new samples"
   ],
   "metadata": {
    "id": "Nr7B-RLwQr9Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "import os\n",
    "\n",
    "def gpt3(prompt):\n",
    "    response = openai.Completion.create(\n",
    "        model=\"text-davinci-003\",\n",
    "        prompt=prompt,\n",
    "        temperature=0.7,\n",
    "        max_tokens=300,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    if response:\n",
    "        if response.choices and response.choices[0]:\n",
    "            res = response.choices[0].text.strip()\n",
    "            return res\n",
    "    return None\n",
    "\n",
    "def write_test_sets_with_context(test_sets_dir, test_sets_generated_context_dir, output_prompt_filename):\n",
    "  files = os.listdir(test_sets_dir)\n",
    "  jsonl_files = [file for file in files if file.endswith('.jsonl')]\n",
    "\n",
    "  with open (output_prompt_filename, 'r') as prompt_few_shot:\n",
    "    prompt_few_shot_content = prompt_few_shot.read()\n",
    "\n",
    "  for jsonl_file in jsonl_files:\n",
    "    jsonl_file_full_path = os.path.join(test_sets_dir, jsonl_file)\n",
    "    situations = read_situation_from_json(jsonl_file_full_path, False)\n",
    "    for situation in situations:\n",
    "      prompt = prompt_few_shot_content + '\\n' + \"SITUATION: \" + situation['question']\n",
    "      res = gpt3(prompt)\n",
    "      elaborations = res.split(\"ELABORATIONS:\")[1]\n",
    "      elaborations = elaborations.replace('\\n', ' ')\n",
    "      situation['context'] = elaborations\n",
    "\n",
    "      output_file_full_path = os.path.join(test_sets_generated_context_dir, jsonl_file.split('.')[0] + \"_gpt3_generate_context\" + \".jsonl\")\n",
    "      with open(output_file_full_path, 'a') as output_file:\n",
    "        output_file.write(json.dumps(situation) + '\\n')\n",
    "\n",
    "output_prompt_filename = '/content/drive/MyDrive/MacawProject/dimensions_prompt.txt'\n",
    "test_sets_dir = '/content/drive/MyDrive/MacawProject/test_sets'\n",
    "test_sets_generated_context_dir = '/content/drive/MyDrive/MacawProject/test_sets_generated_context'\n",
    "write_test_sets_with_context(test_sets_dir, test_sets_generated_context_dir, output_prompt_filename)\n"
   ],
   "metadata": {
    "id": "-aLCLpVZ1AxJ"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Generate COT for commonsense dataset using GPT3"
   ],
   "metadata": {
    "id": "oMROPP85FiVe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "commonsense_generated_context_path = '/content/drive/MyDrive/MacawProject/test_sets_generated_context/commonsense_qa_gpt3_generate_context.jsonl'\n",
    "prompt_prefix = \"You are given a multiple-choice task. Given a question, and a context, you should choose the best answer to the question out of different options. Please include the answer only and not the label of the option. For example for the options (A) bank (B) library, if you want to answer bank, please reply 'bank'\"\n",
    "\n",
    "\n",
    "def gpt3_w_context():\n",
    "  cot = pd.DataFrame(columns=['id', 'prediction' , 'gt'])\n",
    "  with open(commonsense_generated_context_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        id = data['id']\n",
    "        question = data['question']\n",
    "        answer = data['answer']\n",
    "        mc_options = data['mcoptions']\n",
    "        context = data['context']\n",
    "        prompt = prompt_prefix + '\\n' + 'question: ' + question + '\\n' + 'context: ' + context + '\\n' + 'optional answers: ' + mc_options\n",
    "        print(prompt)\n",
    "        print(\"----\")\n",
    "        res = gpt3(prompt)\n",
    "        cot = cot.append({'id' : id, 'prediction' : res, 'gt' : answer}, ignore_index=True)\n",
    "\n",
    "  cot.to_csv('cot_commonsense_output.csv')\n",
    "  return cot\n",
    "\n",
    "\n",
    "def gpt3_no_context():\n",
    "  cot = pd.DataFrame(columns=['id', 'prediction' , 'gt'])\n",
    "  with open(commonsense_generated_context_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        id = data['id']\n",
    "        question = data['question']\n",
    "        answer = data['answer']\n",
    "        mc_options = data['mcoptions']\n",
    "        prompt = prompt_prefix + '\\n' + 'question: ' + question + '\\n' + 'optional answers: ' + mc_options\n",
    "        print(prompt)\n",
    "        print(\"----\")\n",
    "        res = gpt3(prompt)\n",
    "        cot = cot.append({'id' : id, 'prediction' : res, 'gt' : answer}, ignore_index=True)\n",
    "\n",
    "  cot.to_csv('cot_commonsense_no_context_output.csv')\n",
    "  return cot\n",
    "\n",
    "\n",
    "def print_eval(df):\n",
    "  df['prediction'] = df['prediction'].str.lower()\n",
    "  df['gt'] = df['gt'].str.lower()\n",
    "  df_differ = df[df['prediction'] != df['gt']]\n",
    "  print(df_differ)\n",
    "  proportion = (df['prediction'] == df['gt']).mean()\n",
    "  print('Proportion:', proportion)\n",
    "\n",
    "\n",
    "df_w_context = gpt3_w_context()\n",
    "print_eval(df_w_context)\n",
    "\n",
    "\n",
    "df_no_context = gpt3_no_context()\n",
    "print_eval(df_no_context)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "ulDgevwgBWBf"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}